<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>10. Experimental investigation &mdash; Generalised LR parsing algorithms  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="canonical" href="https://www.xrtero.com/book/glr/10 Experimental investigation.html" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=b3ba4146"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=4825356b"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="11. Concluding remarks" href="11%20Concluding%20remarks.html" />
    <link rel="prev" title="9. Some generalised parser generators" href="9%20Some%20generalised%20parser%20generators.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Generalised LR parsing algorithms
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="1%20Introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="2%20%20Recognition%20and%20parsing.html">2. Recognition and parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="3%20The%20development%20of%20generalised%20parsing.html">3. The development of generalised parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="4%20Generalised%20LR%20parsing.html">4. Generalised LR parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="5%20Right%20Nulled%20Generalised%20LR%20parsing.html">5. Right Nulled Generalised LR parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="6%20Binary%20Right%20Nulled%20Generalised%20LR%20parsing.html">6.Binary Right Nulled Generalised LR parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="7%20Reduction%20Incorporated%20Generalised%20LR%20parsing.html">7.Reduction Incorporated Generalised LR parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="8%20Other%20approaches%20to%20generalised%20parsing.html">8 Other approaches to generalised parsing</a></li>
<li class="toctree-l1"><a class="reference internal" href="9%20Some%20generalised%20parser%20generators.html">9. Some generalised parser generators</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">10. Experimental investigation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#overview-of-chapter">10.1 Overview of chapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-grammar-tool-box-and-parser-animation-tool">10.2 The Grammar Tool Box and Parser Animation Tool</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-grammars">10.3 The grammars</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-input-strings">10.4 The input strings</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parse-table-sizes">10.5 Parse table sizes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-performance-of-the-rnglr-algorithm-compared-to-the-tomita-and-farshi-algorithms">10.6 The performance of the RNGLR algorithm compared to the Tomita and Farshi algorithms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#a-non-cubic-example">A non-cubic example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-different-lr-tables">10.6.2 Using different LR tables</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#the-performance-of-farshi-s-algorithms">10.6.3 The performance of Farshi’s algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-performance-of-the-brnglr-algorithm">10.7 The performance of the BRNGLR algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#gss-construction">10.7.1 GSS construction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sppf-construction">10.7.2 SPPF construction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#the-performance-of-earley-algorithm">10.8 The performance of Earley algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-performance-of-the-riglr-algorithm">10.9 The performance of the RIGLR algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#the-size-of-ria-and-rca">10.9.1 The size of RIA and RCA</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asymptotic-behaviour">10.9.2 Asymptotic behaviour</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="11%20Concluding%20remarks.html">11. Concluding remarks</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Generalised LR parsing algorithms</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">10. Experimental investigation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/10 Experimental investigation.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="experimental-investigation">
<h1>10. Experimental investigation<a class="headerlink" href="#experimental-investigation" title="Permalink to this heading">¶</a></h1>
<p>This chapter presents the experimental results based on eight of the generalised parsing algorithms described in this thesis: RNGLR, BRNGLR, RIGLR, Tomita1e, Tomita1e modified, Farshi naive, Farshi optimised and Earley. Several pathological grammars are used to trigger the algorithms’ worst case behaviour and three programming language grammars are used to gauge their performance in practice. All the algorithms’ results are given for the recognition time and space required, while the RNGLR and BRNGLR results include statistics on the SPPF construction.</p>
<section id="overview-of-chapter">
<h2>10.1 Overview of chapter<a class="headerlink" href="#overview-of-chapter" title="Permalink to this heading">¶</a></h2>
<p>In Chapter 4 we discussed Tomita’s GLR parsing algorithms, specifically focusing on his Algorithm 1, that only works for <span class="math notranslate nohighlight">\(\epsilon\)</span>-free grammars, and Farshi’s extension that works for all grammars. We have implemented Farshi’s algorithm exactly as it is described in [10], and we have also implemented a more efficient version which truncates the searches in the GSS as described in Chapter 4. We refer to the former as Farshi-naive and the latter as Farshi-opt. We present the results for both algorithms in Section 10.6.</p>
<p>In Chapter 5 we discussed a minor modification, Algorithm 1e, of Tomita’s Algorithm 1, which admits grammars with <span class="math notranslate nohighlight">\(\epsilon\)</span>-rules. On right nullable grammars, Algorithm 1e performs less efficiently with RN parse tables than LR(1) parse tables (although of course sometimes it performs incorrectly on LR(1) tables). We have a modified algorithm (Algorithm 1e mod) which is actually more efficient on RN tables than Algorithm 1e is on the LR(1) table.</p>
<p>We now present experimental data comparing the performance of the different algorithms. RNGLR is compared to Farshi, as these are the two fully general GLR algorithms. However, even with the modifications mentioned above, Farshi’s algorithm is not as efficient as Tomita’s algorithm, thus the RNGLR algorithm is also compared to Tomita’s original approach using Algorithm 1e.</p>
<p>The BRNGLR algorithm is asymptotically faster than the RNGLR algorithm in worst case and data showing this is given. Experiments are also carried out on average cases using Pascal, Cobol and C grammars, to investigate typical as well as worst case performance. The BRNGLR algorithm is also compared to Earley’s classic cubic general parsing algorithm and to the cubic RIGLR algorithm, as this was designed to have reduced constants of proportionality by limiting the underlying stack activity.</p>
<p>We also present data comparing the relative efficiency of the GLR algorithms when different types (LR(0), SLR(1), LALR(1) and LR(1)) of parse table are used.</p>
</section>
<section id="the-grammar-tool-box-and-parser-animation-tool">
<h2>10.2 The Grammar Tool Box and Parser Animation Tool<a class="headerlink" href="#the-grammar-tool-box-and-parser-animation-tool" title="Permalink to this heading">¶</a></h2>
<p>The Grammar Tool Box (GTB) [15] is a system for studying language specification and translation. GTB includes a set of built-in functions for creating, modifying and displaying structures associated with parsing.</p>
<p>The Parser Animation Tool (PAT) is an accompanying visualisation tool that has its own implementations of the parsing algorithms discussed in this thesis which run from tables generated by GTB. PAT is written in Java, and GTB in C++ so they necessarily require separate implementations, but this has the added benefit of two authors constructing independent programs from the theoretical treatment. PAT dynamically displays the construction of parse time structures and can also be used in batch mode to generate statistics on parser behaviour. The results presented in this chapter have been generated in this way. A guide to PAT and its use is given in Appendix A.</p>
<p>The complete tool chain conducted for this thesis comprises of ebnf2bnf, a tool for converting extended BNF grammars to BNF; GTB which is used to analyse grammars and construct parse tables, and PAT which is used to animate algorithms and generate statistics on parse-time structure size.</p>
</section>
<section id="the-grammars">
<h2>10.3 The grammars<a class="headerlink" href="#the-grammars" title="Permalink to this heading">¶</a></h2>
<p>Pascal and C typify the top-down and bottom-up approaches to language design. In folklore at least, Pascal is thought of as being designed for LL(1) parsing and C for LALR(1) parsing. In practice, Pascal is reasonably close to LL(1). Our Pascal grammar only has one SLR(1) conflict, arising from the <em>if-then-else</em> ambiguity. C is essentially parsable with an LALR(1) parser, but was not initially designed that way. The LALR(1) ANSI-C grammar was only written by Tom Penello in about 1983. Bjarne Stroustrup described at some length the difficulties involved in attempting to build parsers for early versions of C++ using a hybrid of Yacc and a lexer containing much lexical trickery relying on recursive descent techniques [12, p.68]. C++’snon-deterministic syntax has clearly stimulated the development of tools such as ANTLR [11] and the GLR mode of Bison [12]. Cobol’s development was contemporary with that of Algol-60 and thus pre-dates the development of deterministic parsing techniques. The language has a large vocabulary which will challenge any table based parsing method.</p>
<p>For these experiments we have used the grammar for ISO-7185 Pascal extracted from the standard, the grammar for ANSI-C extracted from [10] and a grammar for IBM VS-Cobol developed in Amsterdam. This grammar is described in [11]. A version of the grammar is available as a hyperlinked browsable HTML file from [Cob]: we used a version prepared for Asf+Sdf from which we extracted the context-free rules. The original grammars are written in EBNF. The ebnf2bnf tool was used to generate corresponding BNF grammars. See [12] for more details of this tool.</p>
<p>To demonstrate the non-cubic behaviour of the RNGLR, Farshi and Tomita 1e algorithms we have used Grammar 6.1 (see page 118), which is discussed in detail in Chapter 6.</p>
</section>
<section id="the-input-strings">
<h2>10.4 The input strings<a class="headerlink" href="#the-input-strings" title="Permalink to this heading">¶</a></h2>
<p>For all the input strings used in the experiments we have suppressed lexical level productions and used separate tokenisers to convert source programs into strings of terminals from the main grammar. For instance the Pascal fragment</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082017364.png" /></p>
<p>For Pascal, our source was two versions of a tree viewer program with 4,425 and 4,480 tokens respectively, and a quadratic root calculator with 429 tokens; for ANSI-C a Boolean equation minimiser of 4,291 tokens; and for Cobol, two strings extracted from the test set supplied with the grammar consisting of 56 and 2,196 tokens respectively.</p>
<p>The tokeniser’s inability to distinguish between identifiers and type names in C has meant that our C grammar does not distinguish them either. This is the reason for the high number of LR(1) conflicts in the grammars.</p>
<p>The parses for Grammar 6.1 are performed on strings of <span class="math notranslate nohighlight">\(b\)</span>’s of varying lengths.</p>
</section>
<section id="parse-table-sizes">
<h2>10.5 Parse table sizes<a class="headerlink" href="#parse-table-sizes" title="Permalink to this heading">¶</a></h2>
<p>This section compares the sizes of the LR(0), SLR(1), LALR(1) and LR(1) parse tables with the corresponding RN tables for our ANSI-C, Pascal and Cobol grammars.</p>
<p>Recall from Chapter 5 that the RNGLR algorithm corrects the problem with Tomita’s Algorithm 1e by performing nullable reductions early. This is achieved through the modification of the LR parse table. For a given combination of grammar and LR(0), SLR(1), LALR(1), or LR(1) parse table, the GSS constructed during a parse will be the same size for both RN- and conventional Knuth-style reductions. In general the RN tables will contain far more conflicts, which might be expected to generate more searching during the GSS construction. In Section 10.6 we shall show that, contrary to intuition, the RNGLR algorithm performs better than either Tomita or Farshi’s algorithms. In fact it reduces the stack activity compared to the standard LR parsing algorithm for grammars that contain right nullable rules. The LR(0), SLR(1), LALR(1), LR(1), and RN parse tables for each of the programming language grammars are shown in Tables 10.1, 10.2 and 10.3.
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082017146.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082017842.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082018163.png" /></p>
<p>Coвol requires more than seven times as many states as ANSI-C for LR(0) and SLR(1) tables. In fact GTB’s LR(1) table generator ran out of memory when processing CoBOL, so we leave those entries empty. GTB builds LALR(1) parse tables by merging <span class="math notranslate nohighlight">\(\operatorname{LR}(1)\)</span> tables so those entries for CoBOL are also blank. We see that this CоBOL grammar is highly non-deterministic, reflecting the construction process described in [LV01].
We now consider how the use of different parse tables affects the size of the GSS constructed by our GLR algorithms. Tables 10.4, 10.5 and 10.6 present the number of GSS nodes and edges created during the parse of the C, Pascal and CoBoL input strings respectively.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082020151.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082021262.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082021198.png" /></p>
<p>The Tomita, Farshi and RNGLR algorithms generate the same structures. The BRNGLR algorithm achieves cubic run times but at the cost of a worst-case constant factor increase in the size of the structures. For any grammar with productions greater than two symbols long the BRNGLR algorithm introduces additional nodes into the GSS. The results show increases of around 10 % in the size of the structures.
There is a potential trade off between the amount of nondeterminism in the table and the size of the GSS. Some early reports, [Lan91], [BL89], suggest that LR(1) based GSS’s would be much larger than SLR(1) ones because the number of states is so much larger, and in the limit, the number of nodes in a GSS is bounded by the product of the number of table states and the length of the string.
However, this is not necessarily the case. The above tables show LR(1) GSS’s that are a little smaller than the corresponding SLR(1) ones. Of course, the LR(1) tables themselves are usually much bigger than SLR(1) tables so the rather small reduction in GSS size might only be justified for very long strings. The AsF+SDF Meta Environment uses SLR(1) tables.
In the next section we turn our attention to the performance of the GLR algorithms and show how the use of different parse tables affects the performance of the Tomita, Farshi and RNGLR algorithms. Of course, there are pathological cases where the size of an LR(1) GSS is much greater than the corresponding SLR(1) GSS. See [JSE04b].</p>
</section>
<section id="the-performance-of-the-rnglr-algorithm-compared-to-the-tomita-and-farshi-algorithms">
<h2>10.6 The performance of the RNGLR algorithm compared to the Tomita and Farshi algorithms<a class="headerlink" href="#the-performance-of-the-rnglr-algorithm-compared-to-the-tomita-and-farshi-algorithms" title="Permalink to this heading">¶</a></h2>
<p>Tomita’s Algorithm 1 was only designed to work on <span class="math notranslate nohighlight">\(\epsilon\)</span>-free grammars. We have presented a straightforward extension to his algorithm to allow it to handle grammars containing <span class="math notranslate nohighlight">\(\epsilon\)</span>-rules. Unfortunately this extended algorithm, which we have called Algorithm 1e, may fail to correctly parse grammars with hidden-right recursion. As mentioned in Section 10.1 we have discussed a slightly more efficient version, Algorithm 1e mod, of Algorithm 1e.</p>
<p>In Chapter 5 we discussed the RNGLR algorithm and showed how it extends Tomita’s Algorithm 1 to parse all context-free grammars. Our technique is not the first attempt to fully generalise Tomita’s algorithm (see Chapter 4). Farshi presented a ‘brute-force’ algorithm which handles all context-free grammars. However, his approach introduces a lot of extra searching. Here we compare the efficiency of Farshi’s algorithm with the RNGLR algorithm. Because Farshi’s algorithm is not efficient we also compare RNGLR with Algorithm 1e.</p>
<p>To compare the efficiency of the GSS construction between the different algorithms, the number of edge visits performed during the application of a reduction are counted. An edge visit is only counted when tracing back all possible paths during a reduction. The creation of an edge is not counted as an edge visit. Recall that in the RNGLR and Algorithm 1e mod algorithms the first edge in a reduction path is not visited because of the way pending reductions are stored in the set <span class="math notranslate nohighlight">\(\mathcal{R}\)</span>.</p>
<section id="a-non-cubic-example">
<h3>A non-cubic example<a class="headerlink" href="#a-non-cubic-example" title="Permalink to this heading">¶</a></h3>
<p>We begin by discussing the results for parses of strings <span class="math notranslate nohighlight">\(b^{d}\)</span> in Grammar 6.1. This grammar has been shown to trigger worst case behaviour for the GLR-style algorithms (see Chapter 6).
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082022885.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082023551.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082023814.png" />
As we can see, all of the algorithms perform badly as expected, but Farshi’s naive version is much worse than the others. However, the GSS produced by each of the algorithms should be the same and the figures in Table 10.8 support this expectation.</p>
</section>
<section id="using-different-lr-tables">
<h3>10.6.2 Using different LR tables<a class="headerlink" href="#using-different-lr-tables" title="Permalink to this heading">¶</a></h3>
<p>In this section we compare the GSS construction costs when different types of LR tables are used.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082023780.png" /></p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082023662.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082023277.png" /></p>
<p>GTB and PAT have allowed us to make direct comparisons between the Tomita, Farshi and RNGLR algorithms and three types of LR table. In all cases the LR(1) table resulted in smaller and faster run-time parsers, but the improvement over SLR(1) is not very big, while the increase in the size of the table is significant. Of course, there are pathological cases where the size of an LR(1) GSS is much greater than the corresponding SLR(1) GSS. For example, consider Grammar 10.1 and Grammar 10.2. Both grammars illustrate situations in which all three DFA types are equally bad, but the LR(1) tables result in smaller GSS’s being constructed than for the SLR(1) tables.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082024324.png" /></p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082112416.png" /></p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082112595.png" /></p>
<p>Table 10.14 shows that there is a significant difference in the run-time cost of a parse for Grammars 10.1 using the LR(1) parse table compared to the SLR(1) and LR(0) parse tables.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082112196.png" />
Table 10.14: Edge visits performed parsing strings of the form bd in Grammar 10.1.
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082112616.png" />
Table 10.15: Edge visits performed parsing strings of the form <span class="math notranslate nohighlight">\(b^d\)</span> in Grammar 10.2.</p>
</section>
</section>
<section id="the-performance-of-farshi-s-algorithms">
<h2>10.6.3 The performance of Farshi’s algorithms<a class="headerlink" href="#the-performance-of-farshi-s-algorithms" title="Permalink to this heading">¶</a></h2>
<p>Although we expected the RNGLR algorithm to carry out significantly fewer edge visits than the either of the Farshi algorithms, it was surprising that the number of edge visits for the naive version of Farshi were so similar to the optimised version for ANSI-C and Pascal. To get a better understanding of the results, PAT was used to output diagnostics of the algorithm’s performance.</p>
<p>The optimised version of Farshi only triggers a saving when a new edge is added to an existing node in the current level of the GSS and the length of the reduction that is reapplied is greater than one. Therefore, if the majority of reductions performed have a length less than two, it is likely that the saving will not be as good as expected. To help reason about this behaviour PAT was used to create histograms of the number of times a reduction of length <span class="math notranslate nohighlight">\(i\)</span> was added to the set <span class="math notranslate nohighlight">\(\mathcal{R}\)</span> for the ANSI-C and Pascal experiments. The two histograms are shown in Figures 10.2 and 10.3. Their x-axis represents the reduction length and the y-axis the number of times a reduction was added to the set <span class="math notranslate nohighlight">\(\mathcal{R}\)</span>.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082114161.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082114378.png" /></p>
<p>Both histograms show that the majority of reductions performed are of length one which explains why the results are so similar.</p>
<p>The number of edge visits performed parsing strings in Grammar 6.1 differ greatly between the two Farshi algorithms. By counting the number of edge visits contributed by reductions of a certain length, we can see where the optimised version of Farshi is making a saving. We used PAT to generate the histograms in Figures 10.4 and 10.5 that show the number of edge visits performed for reductions of length in Grammar 6.1. The x-axis represents the different reduction lengths and the y-axis the number of edge visits performed.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082114772.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082114983.png" /></p>
<p>For Grammar 6.1 there is a difference of 653,620 edge visits because there are few reductions of length one and none of length zero and the other reductions have triggered a significant saving.</p>
<p>In this section we have shown that the RNGLR algorithm is the most efficient of the algorithms compared. However, its worst case complexity is still <span class="math notranslate nohighlight">\(O(n^{k+1})\)</span> whereas other algorithms that effectively modify the grammar into 2-form claim cubic worst case complexity. The BRNGLR algorithm presented in Chapter 6 is one such technique. Next we compare the efficiency between the RNGLR and BRNGLR algorithms.</p>
</section>
<section id="the-performance-of-the-brnglr-algorithm">
<h2>10.7 The performance of the BRNGLR algorithm<a class="headerlink" href="#the-performance-of-the-brnglr-algorithm" title="Permalink to this heading">¶</a></h2>
<p>This section compares the performance of the BRNGLR and RNGLR parsing algorithms discussed in Chapters 5 and 6 respectively. We present the results of parses for our three programming languages and Grammar 6.1. We begin by discussing the results of the latter experiment which generates worst case behaviour for the BRNGLR algorithm and supra cubic behaviour for the RNGLR algorithm.</p>
<section id="gss-construction">
<h3>10.7.1 GSS construction<a class="headerlink" href="#gss-construction" title="Permalink to this heading">¶</a></h3>
<p>The number of edge visits performed by each algorithm are shown in Table 10.16. Recall that, for both algorithms, the creation of an edge is not counted as an edge visit and the first edge in a reduction path is not visited because of the way pending reductions are stored in the set <span class="math notranslate nohighlight">\(\mathcal{R}\)</span>. As it is sometimes difficult to distinguish between data that has been generated by a cubic, quartic or other polynomial function, the edge visit ratio, which we expect to be linear, is also presented.
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082115962.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082115772.png" />
Because of the regularity of Grammar 6.1 we can compute by hand, the number of edge visits made by the BRNGLR algorithm on <span class="math notranslate nohighlight">\(b^{d}\)</span>. For <span class="math notranslate nohighlight">\(d\geq 3\)</span>, the number is
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082115340.png" /></p>
<p>The experimental results do indeed fit this formula. Table 10.16 only shows a sample of the data gathered. In fact the algorithm was run for all strings <span class="math notranslate nohighlight">\(b^{d}\)</span> for lengths from 1 to 200. This data was exported to Microsoft Excel and used to generate two polynomial trend-lines for the data gathered for both algorithms. Using the RNGLR trend-line we have generated the following formula for the number of RNGLR edge visits, which matches the 201 data points exactly. As expected it is a quartic polynomial.</p>
<p>It is worth noting here that the BRNGLR algorithm implementation parsed <span class="math notranslate nohighlight">\(b^{1000}\)</span> in less than 20 minutes, while the ‘GLR’ version of Bison could not parse <span class="math notranslate nohighlight">\(b^{20}\)</span>.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082116795.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082116520.png" /></p>
<p>Whilst the BRNGLR algorithm improves the worst case performance, it is of course important that this improvement is not at the expense of average case behaviour. To demonstrate that the BRNGLR algorithm is not less practical than the RNGLR algorithm we have run both algorithms with all three of our programming language grammars. We expect a similar number of edge visits to be performed for both algorithms.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082116173.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082116504.png" /></p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082117502.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082117550.png" /></p>
</section>
<section id="sppf-construction">
<h3>10.7.2 SPPF construction<a class="headerlink" href="#sppf-construction" title="Permalink to this heading">¶</a></h3>
<p>As we discussed in Section 6.6, the parser version of the BRNGLR algorithm must retain the cubic order of the underlying recogniser. To illustrate this, data was also collected about the space required for the SPPF’s of Grammar 6.1. The number of symbol nodes, additional nodes, packing nodes and edges in the SPPF were recorded. We expect the size of the SPPF generated for Grammar 6.1 by the RNGLR algorithm to be quartic and cubic for the BRNGLR algorithm. To highlight the difference between the two algorithms, the total node ratio, which we expect to be linear, has also been calculated.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082117086.png" />
The BRNGLR algorithm generates SPPF’s an order of magnitude smaller than the RNGLR algorithm for strings in the language of Grammar 6.1. Microsoft Excel was used to generate the following charts of the data.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082118187.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082118190.png" /></p>
<p>The Excel generated equation for the number of packing nodes created by the RNGLR algorithm is</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082118526.png" /></p>
<p>The Microsoft Excel generated equation for the number of packing nodes created by the RNGLR algorithm is
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082119659.png" /></p>
<p>Because of the irregular way packing nodes are created for <span class="math notranslate nohighlight">\(d&lt;4\)</span>, approximation errors occur in the Excel generated charts. By replacing the decimal coefficients with more precise fractions, the correct equation for the number of packing nodes in the RNGLR SPPF can be determined. For <span class="math notranslate nohighlight">\(d&gt;3\)</span> the equation is</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082119876.png" /></p>
<p>Similarly the correct equation for the number of packing nodes in the SPPF generated by the BRNGLR algorithm, for <span class="math notranslate nohighlight">\(d&gt;3\)</span>, is</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082119175.png" />
To show that the average case performance for the generation of SPPF’s is not compromised, SPPF’s were also generated for the ANSI-C, Pascal and Cobol programs previously described.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082119548.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082120593.png" /></p>
<p>The results presented in this section complement the theoretical analysis of the BRNGLR algorithm. In the next section we compare BRNGLR with Earley’s recognition algorithm that is known to also have cubic worst case complexity.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082120693.png" /></p>
</section>
</section>
<section id="the-performance-of-earley-algorithm">
<h2>10.8 The performance of Earley algorithm<a class="headerlink" href="#the-performance-of-earley-algorithm" title="Permalink to this heading">¶</a></h2>
<p>We discussed Earley’s algorithm in Chapter 8. We have implemented his recognition algorithm within PAT and generated statistical data on its performance. We compare the size of the Earley sets with the size of the GSS constructed by the RNGLR and BRNGLR algorithm using an RNLR(1) parse table (except for the Cobol parse which uses an RNSLR(1) table) and the number of symbol comparisons required to construct the Earley sets with the number of edge visits performed by the RNGLR and BRNGLR algorithms.</p>
<p>Earley’s algorithm is known to be cubic in the worst case, quadratic for unambiguous grammars and linear on the class of linear bounded grammars [1]. We begin by comparing the performance of the three algorithms during the parse of strings <span class="math notranslate nohighlight">\(b^{d}\)</span> for Grammar 6.1. Recall that this grammar triggers supra cubic behaviour for the RNGLR algorithm and cubic behaviour for the BRNGLR algorithm. Since it is ambiguous we expect Earley’s algorithm to display at least quadratic behaviour.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082120659.png" />
As expected Earley’s algorithm performs an order of magnitude fewer symbol comparisons than the RNGLR algorithm’s edge visits. It compares well to the BRNGLR algorithm.
Next we present the results of the parses for our three programming languages.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082121984.png" /></p>
<p>Both the RNGLR and the BRNGLR algorithms compare very well to Earley’s algorithm for all of the above experiments.</p>
<p>All of the algorithms that we have compared so far have focused on efficiently performing depth-first searches for non-deterministic sentences. In Chapter 7 we presented the RIGLR algorithm which attempts to improve the parsers’ efficiency by restricting the amount of stack activity. The next section presents the results collected for the parses of the RIGLR algorithm on our four grammars. We compare the performance of the RIGLR algorithm to the RNGLR and BRNGLR algorithms.</p>
</section>
<section id="the-performance-of-the-riglr-algorithm">
<h2>10.9 The performance of the RIGLR algorithm<a class="headerlink" href="#the-performance-of-the-riglr-algorithm" title="Permalink to this heading">¶</a></h2>
<p>The asymptotic and typical actual performance of the RIGLR algorithm is demonstrated by comparing it to the RNGLR and BRNGLR algorithms. We use the grammars for ANSI-C, Pascal and Cobol as well as Grammar 6.1. We begin this section by discussing the size of the RIA’s and RCA’s constructed by GTB and used by PAT for the experiments.</p>
<section id="the-size-of-ria-and-rca">
<h3>10.9.1 The size of RIA and RCA<a class="headerlink" href="#the-size-of-ria-and-rca" title="Permalink to this heading">¶</a></h3>
<p>Part of the speed up of the RIGLR algorithm over the RNGLR algorithm is obtained by effectively unrolling the grammar. In a way this is essentially a back substitution of alternates for instances of non-terminals on the right hand sides of the grammar rules. Of course, in the case of recursive non-terminals the back substitution process does not terminate, which is why such instances are terminalised before the process begins.</p>
<p>We terminalised and then built the RIA’s and RCA’s for ANSI-C, Pascal, Cobol and Grammar 6.1 described above. In each case the grammars were terminalised so that all but non-hidden left recursion was removed before constructing the RIA’s. Table 10.31 shows the number of terminalised non-terminals, the number of instances of these terminalised non-terminals in the grammar, the number of symbol labelled transitions in RCA(<span class="math notranslate nohighlight">\(\Gamma\)</span>) and the number of reduction labelled transitions in RCA(<span class="math notranslate nohighlight">\(\Gamma\)</span>). (It is a property of RCA(<span class="math notranslate nohighlight">\(\Gamma\)</span>) that the number of states is equal to the number of symbol labelled transitions + the number of terminalised nonterminal instances + 1.)</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082123605.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082123072.png" /></p>
<p>The size of some RIA’sThe size of the RCA’s for ANSI-C and Cobol are impractically large. The potential explosion in automaton size is not of itself surprising: we know it is possible to generate an LR(0) automaton which is exponential in the size of the grammar. The point is that the examples here are not artificial. Some properties of grammars that cause this kind of explosion to occur are discussed in detail in [13]. The construction of these automata is made difficult because of their size. In particular, the approach of constructing the RCA by first constructing the IRIA’s and RIA, as presented in Chapter 7, can be particularly expensive. A more efficient construction approach that involves performing some aspects of the subset construction ‘on-the-fly’ is presented in [JSE04a].</p>
<p>Ultimately the way to control the explosion in the size of RCA is to introduce more non-terminal terminalisations. In order for the RIGLR algorithm to be correct, it is necessary to terminalise the grammar so that no self embedding exists, but the process is still correct if further terminalisations are applied.</p>
<p>Although this will reduce the size of parser for some grammars, it comes at the cost of introducing more recursive calls when the parser is run and hence the (practical but not asymptotic) run time performance and space requirements of the parser will be increased. Thus there is an engineering tradeoff to be made between the size of the parser and its performance.</p>
</section>
<section id="asymptotic-behaviour">
<h3>10.9.2 Asymptotic behaviour<a class="headerlink" href="#asymptotic-behaviour" title="Permalink to this heading">¶</a></h3>
<p>To measure the run-time performance of the RNGLR and BRNGLR algorithms we count the number of edge visits performed for the application of reductions, in the way described in Section 10.6. For the space required we count the number of state nodes and edges in the GSS as well as the maximum size of the set <span class="math notranslate nohighlight">\(\mathcal{R}\)</span>. For the RIGLR algorithm we measure the run-time performance by counting the number of RCA edge visits performed during the execution of pop actions and the space by the total number of elements added to the set <span class="math notranslate nohighlight">\(U_{i}\)</span>.</p>
<p>Figure 10.11 and Table 10.33 present the number of edge visits performed by RNGLR, BRNGLR and RIGLR algorithms for parses of the string <span class="math notranslate nohighlight">\(b^{d}\)</span> in Grammar 6.1. The RIGLR and BRNGLR algorithms display cubic time complexity whereas the RNGLR algorithm displays quartic time complexity.</p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082123236.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082124951.png" /></p>
<p><img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082124644.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082124912.png" />
<img alt="image.png" src="https://blog-1314253005.cos.ap-guangzhou.myqcloud.com/202310082125202.png" /></p>
<p>The size of the structures constructed during the parses by the separate algorithms indicate that the RIGLR algorithm achieves an order of magnitude reduction of space compared to the RNGLR and BRNGLR algorithms. The examples also show that the number of edge visits performed by the RIGLR algorithm compare well to the results of the RNGLR and BRNGLR algorithms.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="9%20Some%20generalised%20parser%20generators.html" class="btn btn-neutral float-left" title="9. Some generalised parser generators" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="11%20Concluding%20remarks.html" class="btn btn-neutral float-right" title="11. Concluding remarks" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, xrtero.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>